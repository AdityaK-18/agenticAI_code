{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACKING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPEN_API_KEY\"] = os.getenv(\"OPEN_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "LANGSMITH_TRACING=\"true\"\n",
    "LANGSMITH_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "LANGSMITH_API_KEY= os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGSMITH_PROJECT= os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "OPENAI_API_KEY= os.getenv(\"OPEN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(llm)\n",
      "File \u001b[1;32mc:\\Users\\aditya.kumar\\agentic_AI_workshop\\.venv\\Lib\\site-packages\\langchain_core\\load\\serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\aditya.kumar\\agentic_AI_workshop\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:562\u001b[0m, in \u001b[0;36mBaseChatOpenAI.validate_environment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mClient(proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy)\n\u001b[0;32m    561\u001b[0m     sync_specific \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client}\n\u001b[1;32m--> 562\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msync_specific\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client:\n",
      "File \u001b[1;32mc:\\Users\\aditya.kumar\\agentic_AI_workshop\\.venv\\Lib\\site-packages\\openai\\_client.py:110\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    108\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is agentic AI\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"What is agentic AI\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic AI refers to artificial intelligence systems that possess a certain degree of autonomy or agency, meaning they can make decisions and take actions without direct human intervention in pursuit of specific goals. These systems are designed to perceive their environment, process information, and perform tasks with some level of independence. \n",
      "\n",
      "Agentic AI can vary greatly in complexity, from simple rule-based systems to more advanced models that incorporate machine learning, enabling them to adapt and improve their performance over time. Such systems are typically used in applications where decision-making needs to be done rapidly, across a wide range of potential scenarios, or where humans cannot be directly involved due to scale or complexity.\n",
      "\n",
      "The concept of agentic AI often raises discussions about ethical considerations, such as accountability, control, transparency, and the impact on employment and society. This is particularly relevant as AI systems with more advanced agentic capabilities continue to develop.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='you are an expert AI Engineer, provide me answer'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"you are an expert AI Engineer, provide me answer\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model= \"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Certainly! LangChain is a framework designed to simplify the development of applications using large language models (LLMs). It provides a suite of tools and abstractions that make it easier to integrate LLMs into various applications and workflows. Here are some key features and components that LangChain typically includes:\\n\\n1. **Modular Components**: LangChain offers modular components that allow developers to connect different pieces required for a functioning LLM application. This includes things like prompt templates, response parsing, and interaction with external APIs or data sources.\\n\\n2. **Chain of Operations**: The term \"chain\" in LangChain refers to a sequence of operations or processes that handle the input data, pass it through an LLM, and manage the output. This can include pre-processing steps, multiple LLM calls, and integration with other computational components for complex workflows.\\n\\n3. **Prompt Management**: LangChain often provides utilities to manage prompts efficiently. This can include templating systems that allow dynamic generation of prompts based on user data or context, which helps to maintain consistency and relevance in interactions.\\n\\n4. **Memory Management**: Some implementations of LangChain may include memory components that facilitate state management across interactions. This is crucial for applications that need to maintain context over a session, such as chatbots or conversational agents.\\n\\n5. **Tool Integration**: LangChain is often built to work well with various third-party tools and libraries, allowing for seamless integration into existing tech stacks. This can include things like connecting to databases, APIs, or other external systems to enrich the functionality of the LLM application.\\n\\n6. **Multi-Model Support**: To accommodate different use cases and performance requirements, LangChain may support multiple LLMs, allowing developers to switch or combine different models based on their specific needs.\\n\\nIn summary, LangChain is designed to help developers streamline the process of building and deploying applications with large language models by providing a structured approach to managing the different components involved in utilizing LLMs effectively.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 400, 'prompt_tokens': 29, 'total_tokens': 429, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'stop', 'logprobs': None} id='run-04572f3f-ab79-4045-a37b-70013e3bd722-0' usage_metadata={'input_tokens': 29, 'output_tokens': 400, 'total_tokens': 429, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt|llm\n",
    "response = chain.invoke({\"input\":\"can you explain what is langchain?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a framework designed to simplify the development of applications using large language models (LLMs). It provides tools and abstractions that facilitate the integration and orchestration of various components commonly used in conjunction with language models. The goal of LangChain is to make it easier for developers to build complex, language-powered applications by providing a structured approach to managing tasks such as prompt engineering, model selection, data handling, and deployment.\n",
      "\n",
      "Key features of LangChain include:\n",
      "\n",
      "1. **Prompt Management**: LangChain offers utilities to manage prompts, allowing developers to create, customize, and test prompts for different LLMs effectively.\n",
      "\n",
      "2. **Model Wrappers**: It provides abstractions that simplify the interaction with various LLMs, making it easier to switch between models or integrate multiple models within the same application.\n",
      "\n",
      "3. **Memory**: The framework supports memory management, enabling applications to maintain the context across interactions, which is crucial for creating conversational agents that understand and remember past interactions.\n",
      "\n",
      "4. **Chaining**: LangChain introduces the concept of \"chains,\" a mechanism to link together a sequence of operations or model calls, allowing for more complex workflows and logic.\n",
      "\n",
      "5. **Integrations**: It offers integrations with popular libraries and tools commonly used in the AI ecosystem, such as data-processing libraries, storage solutions, and deployment platforms.\n",
      "\n",
      "By providing structured components and a cohesive framework, LangChain aims to reduce the complexity involved in developing applications that leverage the power of large language models, enabling developers to focus more on building unique, value-added features rather than dealing with the intricacies of managing LLMs.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt|llm|output_parser\n",
    "response = chain.invoke({\"input\":\"can you explain what is langchain?\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "\n",
    "    ]\n",
    ")\n",
    "prompt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is not a widely recognized concept or term as of my last update in October 2023. It is possible that \"Langsmith\" may refer to a new or niche software tool, programming framework, or concept that emerged after my last update, or it could be a fictional or hypothetical scenario. \\n\\nIf \"Langsmith\" pertains to programming or AI, it might be a name given to a specific tool or framework related to language processing, development, or a similar field. Given the context, it could be a system designed to work with languages—whether programming languages or natural languages—possibly offering tools for development, manipulation, or analysis.\\n\\nFor the most accurate and up-to-date information, I would recommend checking current resources or official documentation related to \"Langsmith\" if it\\'s a proprietary tool or concept that has gained recognition after my last update.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 172, 'prompt_tokens': 32, 'total_tokens': 204, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_523b9b6e5f', 'finish_reason': 'stop', 'logprobs': None} id='run-116e805f-78f3-42de-a122-4a0399c2d58e-0' usage_metadata={'input_tokens': 32, 'output_tokens': 172, 'total_tokens': 204, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is not a widely recognized concept or term as of my last update in October 2023. It is possible that \"Langsmith\" may refer to a new or niche software tool, programming framework, or concept that emerged after my last update, or it could be a fictional or hypothetical scenario. \n",
      "\n",
      "If \"Langsmith\" pertains to programming or AI, it might be a name given to a specific tool or framework related to language processing, development, or a similar field. Given the context, it could be a system designed to work with languages—whether programming languages or natural languages—possibly offering tools for development, manipulation, or analysis.\n",
      "\n",
      "For the most accurate and up-to-date information, I would recommend checking current resources or official documentation related to \"Langsmith\" if it's a proprietary tool or concept that has gained recognition after my last update.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a toolkit developed by LangChain designed to aid developers in debugging and monitoring applications that utilize large language models (LLMs). It provides a suite of features to streamline evaluation, testing, and monitoring, with a focus on LLMs and chains of LLM calls.\n",
      "\n",
      "Key features of Langsmith include:\n",
      "\n",
      "1. **Developer-Focused Tools**: The toolkit offers instruments for logging, debugging, and testing during the development process of LLMs. This supports developers in fine-tuning and ensuring accurate performance of their language model applications.\n",
      "\n",
      "2. **Data-Centric Approach**: Langsmith is designed with a strong emphasis on data, allowing developers to analyze application performance thoroughly and cultivate iterative improvements based on empirical insights.\n",
      "\n",
      "3. **Integration with LangChain**: By integrating smoothly with LangChain, Langsmith forms part of a wider ecosystem that simplifies the development of AI applications, ensuring reliability and efficiency through extensive tools and libraries.\n",
      "\n",
      "This toolbox is a part of LangChain's broader mission to offer robust solutions for developing sophisticated language model applications, addressing the complexities and challenges associated with managing and deploying large-scale language models.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "output_parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "        template= \"Answer the query.\\n{format_instructions}\\n{query}\\n\",\n",
    "        input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'definition': 'LangChain is a framework designed to assist in the development of applications using large language models (LLMs). It provides a structured environment to harness the capabilities of LLMs for various applications beyond mere text generation, such as chatbots, applications requiring complex reasoning, or natural language processing tasks. LangChain simplifies the integration of LLMs with external data sources, APIs, and simplifies chaining together of multiple tasks.', 'components': {'agents': 'Components that allow LLMs to make decisions about which operations to perform.', 'chains': 'Processes that combine LLM calls with other logical steps to perform complex tasks.', 'memory': 'Components that store state between LLM calls for more coherent conversations or operations.', 'indexers': 'Tools for managing and utilizing large datasets efficiently with LLMs.', 'retrievers': 'Mechanisms to fetch relevant information from datasets based on queries.'}, 'use_cases': ['Building conversational AI or chatbots', 'Developing applications with reasoning capabilities', 'Creating workflows and automations controlled by LLMs', 'Data augmentation for NLP tasks', 'Implementing complex decision-making systems'], 'resources': {'official_website': 'https://www.langchain.com', 'documentation': 'https://docs.langchain.com', 'community_forum': 'https://community.langchain.com'}}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt|llm|output_parser\n",
    "response = chain.invoke({\"query\":\"can you explain what is langchain?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instructions': 'Return a JSON object.'}, template='Answer the query.\\n{format_instructions}\\n{query}\\n')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000249642F7A70>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000024911706A80>, root_client=<openai.OpenAI object at 0x0000024962F5DC10>, root_async_client=<openai.AsyncOpenAI object at 0x00000249642F7110>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| JsonOutputParser()"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.web_base.WebBaseLoader at 0x24917b45bb0>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\"https://www.tigeranalytics.com/\")\n",
    "loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content=\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHome - Tiger Analytics\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle navigation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nServices\\n\\n\\n\\n\\n\\n\\nALL SERVICES \\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\nStrategy & Advisory \\n\\n\\n\\nAnalytics Roadmap \\nData Strategy \\nPlatform Strategy \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nEngineer Your Data \\n\\n\\n\\nData Modernization \\nData Foundation \\nData Operations \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nDifferentiate with AI/ML \\n\\n\\n\\nData Science \\nAI Engineering \\nML Products & Platforms \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nOperationalize Insights \\n\\n\\n\\nExperience Consulting \\nApplication Engineering \\nBusiness Intelligence \\nMLOps \\n\\n\\n\\n \\n\\n\\nIMPACT: MOST RECENT\\n\\n\\n\\nWith a data foundation solution that centralized all data onto one platform, we helped an iconic American CPG brand reduce efforts to improve data quality by 50%.\\nRead more\\n\\n\\n \\n \\n\\nOpen IP\\n\\n\\n\\n\\n\\n\\nOPEN IP \\n \\n \\n\\n\\n\\n\\n\\r\\n\\tFoundations\\r\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTigerML \\n\\n\\n\\tRapidly prototype and deploy intuitive ML models\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\nTiger Blueprints \\n\\n\\n\\tSolve industry-specific business problems\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTiger DataSphere \\n\\n\\tAccelerators that bring speed, automation, and efficiency\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\nTiger AI Hub \\n\\n\\n\\tPre-built use cases and libraries to democratize AI workflows\\n\\n\\n \\n\\n\\n \\n \\n\\n\\n\\n\\n\\r\\n\\tSolutions\\r\\n \\n \\n\\n\\n\\n\\n\\n\\n\\r\\n\\t\\t\\tInsights Pro \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tMMX Planner \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tTrendSpotter \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tTPOptimizer \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tForecastPro\\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tUWSmartFill \\n\\n \\n \\n\\nImpact\\n\\n\\n\\n\\n\\n\\r\\n\\tIMPACT\\r\\n \\n \\n\\n\\n\\n\\n\\nIndustries \\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCPG \\n\\n\\nRetail \\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nBFS \\n\\n\\nInsurance \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nManufacturing \\n\\n\\nLogistics \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nLife Sciences \\n\\n\\nHealthcare \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nTechnology, Telecom & Media \\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\r\\n\\tBusiness Functions\\r\\n \\n \\n\\n\\n\\n\\n\\n\\n\\r\\n\\t\\t\\tMarketing \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tCustomer \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tSupply Chain \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tOperations & Planning \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tRisk \\n\\n \\n \\n\\nAbout Us\\n\\n\\n\\n\\n\\n\\r\\n\\tABOUT US\\r\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAbout us \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nOur Story \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nWhy Join Us \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nCurrent Openings \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nOur Commitment to CSR \\n\\n\\n\\n \\n \\n\\nPartnerships\\n\\n\\n\\n\\n\\n\\r\\n\\tPARTNERSHIPS\\r\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMicrosoft \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nGoogle Cloud \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nAWS \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nDatabricks \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nSnowflake \\n\\n\\n\\n \\n \\n\\nPerspectivesNewsroom\\n\\n\\n\\n\\n\\n\\r\\n\\tNEWSROOM\\r\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNews & PR \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nEvents \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nAwards & Recognitions \\n\\n\\n\\n \\n \\n\\nContact Us  \\n \\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSERVICES\\n\\n\\n\\n\\nGo back\\n\\n\\n\\nSERVICES\\nStrategy & Advisory\\nAnalytics Roadmap\\nData Strategy\\nPlatform Design\\nEngineer Your Data\\nData Modernization\\nData Foundation\\nData Operations\\nDifferentiate with AI/ML\\nData Science\\nAI Engineering\\nML Products & Platforms\\nOperationalize Insights\\nExperience Consulting\\nApplication Engineering\\nBusiness Intelligence\\nMLOps\\n\\n\\n\\n\\nOPEN IP\\n\\n\\n\\n\\nGo back\\n\\n\\n\\nOPEN IP\\nFoundations\\nTigerML\\nTiger Blueprints\\nTiger DataSphere\\nTiger AI Hub\\nSolutions\\nInsights Pro\\nMMX Planner\\nTrendSpotter\\nTPOptimizer\\nForecastPro\\nUWSmartFill\\n\\n\\n\\n\\nIMPACT\\n\\n\\n\\n\\nGo back\\n\\n\\n\\nIndustries\\nCPG\\nRetail\\nBFS\\nInsurance\\nManufacturing\\nTransportation & Logistics\\nLife Sciences\\nHealthcare\\nTechnology, Telecom & Media\\n\\n\\n\\n\\nABOUT US\\n\\n\\n\\n\\nGo back\\n\\n\\n\\nABOUT US\\nOur Story\\nWhy Join Us\\nCurrent Openings\\nOur Commitment to CSR\\n\\n\\n\\n\\nPARTNERSHIPS\\n\\n\\n\\n\\nGo back\\n\\n\\n\\nPARTNERSHIPS\\nMicrosoft\\nGoogle Cloud\\nAWS\\nDatabricks\\nSnowflake\\n\\n\\n\\nPERSPECTIVES\\n\\n\\n\\n\\nNEWSROOM\\n\\n\\n\\n\\nGo back\\n\\n\\n\\nNews & PR\\n\\nEvents\\nAwards\\n\\n\\n\\nCONTACT US\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTiger Analytics awarded the Deloitte India Technology Fast 50 Award 2024\\nRecognized for rapid growth and innovation as one of India’s fastest-growing technology companies.\\nKnow More\\n\\n\\n\\n\\n\\nTiger Analytics Collaborates with Zebra Technologies to Develop GenAI Next-Gen Solutions\\n\\nKnow More\\n\\n\\n\\n\\n\\n\\nVictoria’s Secret and Co. & Tiger Analytics: A Modernization Journey\\nLearn how VS&Co. modernized their analytics ecosystem by migrating from on-prem to Azure and Snowflake\\nRead more\\n\\n\\n\\n\\n\\nTiger Analytics Among India’s Best Workplaces in IT & IT-BPM 2024 and a Certified Great Place to Work®!\\nCommitted to exceptional people practices and fostering a positive work environment.\\nKnow More\\n\\n\\n\\n\\n\\nRanked a Leader and Star Performer in Everest Group PEAK Matrix® Assessment 2024\\nRanked for our strong IP, robust partnerships, and innovative solutions\\nDownload Report\\n\\n\\n\\n\\nTiger Analytics Recognized as a Leader by ISG in Retail Specialty Analytics Services\\n\\nKnow More\\n\\n\\nSCROLL\\n\\n\\n\\n\\nWHAT WE DO\\n\\nWe provide certainty by solving your toughest challenges\\nProblem-solving is not just about finding answers, but also about asking more questions until we know what will determine success and how to get there. Our focus is on helping you drive the right course of action, dispel ambiguity, and move ahead with confidence by bringing the best of AI and analytics together.\\n\\nRead our commitment to you \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat powers us? The Tiger Gene\\nAn attribute intrinsic to the exceptional teams at Tiger Analytics, this helps us unravel complexity and solve some of the toughest problems out there. An ownership mindset in all we do, a future-focused approach to solving problems, bringing the breadth and depth of expertise, and daring to experiment with unconventional methods to ultimately deliver value.\\n\\n\\nSee how we work\\nFind a career with us\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPharma USA 2025\\nConnect with over 1,200 pharma leaders and solution providers at Pharma USA 2025 to explore innovative strategies with Tiger Analytics.\\n\\n\\n\\n\\nMarch 18 - 19, 2025Philadelphia, USA \\nRead More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShoptalk Spring\\nJoin 10,000+ retail innovators at Shoptalk Spring 2025. Discover trends and connect with leaders to transform retail with Tiger Analytics.\\n\\n\\n\\n\\nMarch 25 - 27, 2025Las Vegas, USA \\nRead More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGoogle Cloud Next 2025\\nMeet Tiger Analytics at Next 2025 - Google Cloud's flagship event for technology experts, enthusiasts, and innovators. Spread over three days, you get to discover what’s new and what’s next in gen AI, data, cloud infrastructure, the future of work, security, and more.\\n\\n\\n\\n\\nApril 09 - 11, 2025Las Vegas, USA \\nRead More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSnowflake Summit 2025\\nJoin Tiger Analytics at Snowflake Summit 2025 – the premier event for data cloud enthusiasts and innovators. Across three days, dive into the latest advancements in data engineering, generative AI, analytics, collaboration, and Snowflake’s cutting-edge platform innovations shaping the future of data-driven business.\\n\\n\\n\\n\\nJune 02 - 05, 2025San Francisco, USA \\nRead More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDatabricks Data + AI Summit 2025\\nTiger Analytics invites you to the Databricks Data + AI Summit 2025 – the premier event for data, AI, and analytics enthusiasts. Explore the latest innovations in generative AI, big data, lakehouse platforms, machine learning, and more, shaping the future of data-driven decision-making.\\n\\n\\n\\n\\nJune 09 - 12, 2025San Francisco, USA \\nRead More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDouble Gold for Tiger Analytics at Brandon Hall Group Awards 2024\\nAwarded for the Best Innovative L&D Program (Data Architect Foundation Program) and the Best Results of a Learning Program (Narrative Building Program).\\n\\n\\n\\n\\n\\nLearn More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTiger Analytics Wins Minsky Award for Excellence in AI Strategy Consulting\\nLeading the way in AI-powered business transformation across industries.\\n\\n\\n\\n\\n\\nKnow More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOur Tribe Makes All the Difference\\nWe are certified as a Great Place to Work®️ for yet another year.\\n\\n\\n\\n\\n\\nKnow More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTransform your enterprise data into intelligent action\\n\\n\\n\\n\\n\\nSTRATEGY AND ADVISORY\\nAnalytics Roadmap\\nData Strategy\\nPlatform Strategy\\n\\n\\nKnow more\\n\\n\\n\\n\\n\\nENGINEER YOUR DATA\\nData Modernization \\nData Foundation \\nData Operations\\n\\n\\nKnow more\\n\\n\\n\\n\\n\\nDIFFERENTIATE WITH AI/ML\\nData Science\\nAI Engineering \\nML Products & Platforms\\n\\n\\nKnow more\\n\\n\\n\\n\\n\\nOPERATIONALIZE INSIGHTS\\nExperience Consulting\\nApplication Engineering\\nBusiness Intelligence \\nML Ops\\n\\nKnow more\\n\\n\\n\\n\\n\\n\\n\\n\\nAugmenting industry best practices with AI and analytics\\n\\n\\n\\nEvery industry has its specific challenges, and there are no playbooks for many pressing ones. Balancing best practices and fundamental grounds-up thinking is needed to solve these.\\n\\nStart building now\\n\\n\\n\\n\\n\\n\\n\\n\\nOwn your AI journey with Tiger’s Open IP approach\\n\\n\\n\\nTiger’s easy-to-assemble accelerators and foundations, akin to Lego blocks, help speed up your AI development. As your AI and Analytics strategy evolves, our ready-to-deploy open-box solutions, will help power your growth story ensuring scalability and underscored by quality.\\n\\n\\nStart now\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWe’ve partnered with the best to bring you the latest\\nRead about our partnerships \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGet inspired by the latest in the world of AI and analytics\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWHITE PAPER\\nA Guide to Synthetic Data Generation for Tabular Data\\nLearn how tabular synthetic data generation can address data scarcity and what organizations should consider when selecting vendor partners. \\n\\nDownload the White Paper \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBLOG\\n11 Ways Data Engineers Can Leverage an Agile Mindset to Help Drive Value Efficiently and Effectively\\nThis comprehensive guide explores how Agile methodologies can be applied to data engineering. It outlines key principles such as welcoming change, working in small increments, and continuous improvement. The article provides practical scenarios, pros and cons, and solutions for implementing Agile practices in data engineering projects.\\n\\nRead More  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCASE STUDY\\nTiger Analytics Helps Inspiro Elevate Customer Experience Through a Data-Driven & Azure Open AI Based Knowledge Integration Solution\\nLearn how an OpenAI knowledge base tool built by Tiger Analytics was leveraged to improve Average Handling Time by 30% and Quality Assurance to 99%.\\n\\nLearn More \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBLOG\\nA Guide to Planning, Building and Launching GenAI Projects\\nLearn what questions business leaders need to be asking their teams and what frameworks and guidelines they can use to successfully harness Generative AI for their business.\\n\\nRead More \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBLOG\\nHow Enterprises are Navigating a Brave New Post GenAI Landscape\\nUncover how enterprises are navigating the transformative post-GenAI landscape catalyzed by ChatGPT’s disruption. \\n\\nRead More \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nON-DEMAND WEBINAR\\nStart smart, win fast: Data Expert Talk on Data Modernization\\nIn this insightful webinar, experts from Tiger Analytics and AWS shed light how upgrading your data systems can unlock real-time insights, enhance agility, and provide a competitive edge in customer experience.\\n\\nWatch Webinar \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWHITE PAPER\\nTransforming Conversations, Empowering Businesses\\nLearn how organizations can leverage the potential of Natural Language Processing (NLP) and Generative AI (Gen AI) techniques to derive valuable business insights from customer conversations.\\n\\nDownload the White Paper \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAwards & Recognitions\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMinsky Award for Excellence in AI Strategy Consulting\\n2024\\n\\n\\n\\n\\n\\nDeloitte Technology Fast 50 Award\\n2024\\n\\n\\n \\n\\n\\nDouble Gold for Tiger Analytics at Brandon Hall Group Awards 2024\\n2024\\n \\n\\n\\n\\n\\nMicrosoft Partner of the Year Award for Business Transformation - AI Innovation in ASEAN\\n2024\\n\\n\\n\\n\\n\\nTransforming Agriculture with AI: Tiger Analytics wins nasscom AI Gamechanger Award\\n2024\\n\\n\\n\\n\\n\\nRanked among Financial Times The Americas’ Fastest Growing Companies 2024\\n2024\\n\\n\\n\\n\\n\\nVaishnavi Kandala is recognized as 40 under 40 Data Scientist in India\\n2024\\n\\n\\n\\n\\n\\nLeader in AIM's PeMa Quadrant for Top MLOps Service Providers\\n2024\\n\\n\\n\\n\\n\\nRanked among Financial Times High Growth Companies Asia Pacific\\n2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nUnleash your full potential for a future of infinite possibilities\\nDiscover a meaningful career path in a collaborative environment.\\n\\n\\nApply now \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nServices\\nStrategy & Advisory\\n\\nAnalytics Roadmap\\nData Strategy\\nPlatform Strategy\\n\\nEngineer Your Data\\n\\nData Modernization\\nData Foundation\\nData Operations\\n\\nDifferentiate with AI/ML\\n\\nData Science\\nAI Engineering\\nML Products & Platforms\\n\\nOperationalize Insights\\n\\nExperience Consulting\\nApplication Engineering\\nBusiness Intelligence\\nMLOps\\n\\n\\n\\nOPEN IP\\nFoundations\\n\\nTigerML\\nTiger Blueprints\\nTiger DataSphere\\nTiger AI Hub\\n\\nSolutions\\n\\nInsights Pro\\nMMX Planner\\nTrendSpotter\\nTPOptimizer\\nForecastPro\\nUWSmartFill\\n\\n\\n\\nIMPACT\\nIndustries\\n\\nCPG\\nRetail\\nBFS\\nInsurance\\nManufacturing\\nTransportation & Logistics\\nLife Sciences\\nHealthcare\\nTechnology, Telecom & Media\\n\\n\\n\\n\\n\\n\\nABOUT US\\n\\nOur Story\\nWhy Join Us\\nCurrent Openings\\nOur Commitment to CSR\\n\\n\\nCONTACT US\\nFollow us on\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPartnerships\\n\\nMicrosoft\\nGoogle Cloud\\nAWS\\nDatabricks\\nSnowflake\\nPERSPECTIVES\\n\\n\\nNewsroom\\n\\nNews & PR\\n\\nEvents\\nAwards\\n\\n\\n\\n\\n\\t\\t\\t\\t\\tSubscribe to get latest insights\\n\\t\\t\\t\\t\\t\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tServices\\n\\t\\t\\t\\t\\t\\t\\n\\n\\nSERVICES\\nStrategy & Advisory\\n\\nAnalytics Roadmap\\nData Strategy\\nPlatform Strategy\\n\\nEngineer Your Data\\n\\nData Modernization\\nData Foundation\\nData Operations\\n\\nDifferentiate with AI/ML\\n\\nData Science\\nAI Engineering\\nML Products & Platforms\\n\\nOperationalize Insights\\n\\nExperience Consulting\\nApplication Engineering\\nBusiness Intelligence\\nMLOps\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tOPEN IP\\n\\t\\t\\t\\t\\t\\t\\n\\n\\nOPEN IP\\nFoundations\\n\\nTigerML\\nTiger Blueprints\\nTiger DataSphere\\nTiger AI Hub\\n\\nSolutions\\n\\n\\nInsights Pro\\nMMX Planner\\nTrendSpotter\\nTPOptimizer\\nForecastPro\\nUWSmartFill\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tIMPACT\\n\\t\\t\\t\\t\\t\\t\\n\\n\\nIndustries\\n\\nCPG\\nRetail\\nBFS\\nInsurance\\nManufacturing\\nTransportation & Logistics\\nLife Sciences\\nHealthcare\\nTechnology, Telecom & Media\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tABOUT US\\n\\t\\t\\t\\t\\t\\t\\n\\n\\nABOUT US\\n\\nOur Story\\nWhy Join Us\\nCurrent Openings\\nOur Commitment to CSR\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tPartnerships\\n\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\nMicrosoft\\nGoogle Cloud\\nAWS\\nDatabricks\\nSnowflake\\n\\n\\n\\n\\nPerspectives\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tNewsroom\\n\\n\\n\\n\\n\\nNews & PR\\n\\nEvents\\nAwards\\n\\n\\n\\n\\nCONTACT US\\n\\n\\t\\t\\t\\tSubscribe to get latest insights\\n\\t\\t\\t\\t\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n×\\n\\n\\n\\n\\n\\n\\n\\nThank you!\\nWe will get in touch with you shortly.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n×\\n\\n\\n\\n\\n\\n\\n\\nThank you!\\nThe brochure has been emailed to you.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\tCopyright © 2025 Tiger Analytics | All Rights Reserved\\n\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\nPrivacy Notice\\nCookie Policy\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t        © 2023 TigerAnalytics. All rights reserved. \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tBook my Spot\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n*By submitting your details you acknowledge having read our privacy notice, consent to Tiger Analytics processing your data, and receive communications about Tiger Analytics' resources, events, products, or services.\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat is 6 x 5? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tISG Retail Analytics Provider Lens Report 2024\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n*By submitting your details you acknowledge having read our privacy notice, consent to Tiger Analytics processing your data, and receive communications about Tiger Analytics' resources, events, products, or services.\\n\\n\\n\\nWhat is 3 + 6? \\n\\n\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tISG Supply Chain Analytics Provider Lens Report 2024\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n*By submitting your details you acknowledge having read our privacy notice, consent to Tiger Analytics processing your data, and receive communications about Tiger Analytics' resources, events, products, or services.\\n\\n\\n\\nWhat is 7 x 5? \\n\\n\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tWatch Video\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n*By submitting your details you acknowledge having read our  privacy notice, consent to Tiger Analytics processing your data, and receive communications about Tiger Analytics' resources, events, products, or services.\\n\\n\\n\\nWhat is 1 + 8? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tDownload Brochure\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n*By submitting your details you acknowledge having read our privacy notice, consent to Tiger Analytics processing your data, and receive communications about Tiger Analytics' resources, events, products, or services.\\n\\n\\n\\nWhat is 9 + 6? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tDownload Case Study\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n*By submitting your details you acknowledge having read our privacy notice, consent to Tiger Analytics processing your data, and receive communications about Tiger Analytics' resources, events, products, or services.\\n\\n\\n\\nWhat is 5 + 6? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tDownload Brochure\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n*By submitting your details you acknowledge having read our privacy notice, consent to Tiger Analytics processing your data, and receive communications about Tiger Analytics' resources, events, products, or services.\\n\\n\\n\\nWhat is 5 + 7? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tDownload Brochure\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n*By submitting your details you acknowledge having read our privacy notice, consent to Tiger Analytics processing your data, and receive communications about Tiger Analytics' resources, events, products, or services.\\n\\n\\n\\nWhat is 2 + 9? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tDownload Brochure\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n*By submitting your details you acknowledge having read our privacy notice, consent to Tiger Analytics processing your data, and receive communications about Tiger Analytics' resources, events, products, or services.\\n\\n\\n\\nWhat is 5 + 6? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")]\n"
     ]
    }
   ],
   "source": [
    "document = loader.load()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content='Home - Tiger Analytics\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle navigation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nServices\\n\\n\\n\\n\\n\\n\\nALL SERVICES \\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\nStrategy & Advisory \\n\\n\\n\\nAnalytics Roadmap \\nData Strategy \\nPlatform Strategy \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nEngineer Your Data \\n\\n\\n\\nData Modernization \\nData Foundation \\nData Operations \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nDifferentiate with AI/ML \\n\\n\\n\\nData Science \\nAI Engineering \\nML Products & Platforms \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nOperationalize Insights \\n\\n\\n\\nExperience Consulting \\nApplication Engineering \\nBusiness Intelligence \\nMLOps \\n\\n\\n\\n \\n\\n\\nIMPACT: MOST RECENT\\n\\n\\n\\nWith a data foundation solution that centralized all data onto one platform, we helped an iconic American CPG brand reduce efforts to improve data quality by 50%.\\nRead more\\n\\n\\n \\n \\n\\nOpen IP\\n\\n\\n\\n\\n\\n\\nOPEN IP \\n \\n \\n\\n\\n\\n\\n\\r\\n\\tFoundations\\r\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTigerML \\n\\n\\n\\tRapidly prototype and deploy intuitive ML models\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\nTiger Blueprints \\n\\n\\n\\tSolve industry-specific business problems'),\n",
       " Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content='OPEN IP \\n \\n \\n\\n\\n\\n\\n\\r\\n\\tFoundations\\r\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTigerML \\n\\n\\n\\tRapidly prototype and deploy intuitive ML models\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\nTiger Blueprints \\n\\n\\n\\tSolve industry-specific business problems\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTiger DataSphere \\n\\n\\tAccelerators that bring speed, automation, and efficiency\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\nTiger AI Hub \\n\\n\\n\\tPre-built use cases and libraries to democratize AI workflows\\n\\n\\n \\n\\n\\n \\n \\n\\n\\n\\n\\n\\r\\n\\tSolutions\\r\\n \\n \\n\\n\\n\\n\\n\\n\\n\\r\\n\\t\\t\\tInsights Pro \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tMMX Planner \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tTrendSpotter \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tTPOptimizer \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tForecastPro\\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tUWSmartFill \\n\\n \\n \\n\\nImpact\\n\\n\\n\\n\\n\\n\\r\\n\\tIMPACT\\r\\n \\n \\n\\n\\n\\n\\n\\nIndustries \\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCPG \\n\\n\\nRetail \\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nBFS \\n\\n\\nInsurance \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nManufacturing \\n\\n\\nLogistics \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nLife Sciences \\n\\n\\nHealthcare \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nTechnology, Telecom & Media \\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\r\\n\\tBusiness Functions\\r\\n \\n \\n\\n\\n\\n\\n\\n\\n\\r\\n\\t\\t\\tMarketing \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tCustomer \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tSupply Chain \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tOperations & Planning \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tRisk \\n\\n \\n \\n\\nAbout Us\\n\\n\\n\\n\\n\\n\\r\\n\\tABOUT US'),\n",
       " Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content='Business Functions\\r\\n \\n \\n\\n\\n\\n\\n\\n\\n\\r\\n\\t\\t\\tMarketing \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tCustomer \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tSupply Chain \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tOperations & Planning \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tRisk \\n\\n \\n \\n\\nAbout Us\\n\\n\\n\\n\\n\\n\\r\\n\\tABOUT US\\r\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAbout us \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nOur Story \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nWhy Join Us \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nCurrent Openings \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nOur Commitment to CSR \\n\\n\\n\\n \\n \\n\\nPartnerships\\n\\n\\n\\n\\n\\n\\r\\n\\tPARTNERSHIPS\\r\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMicrosoft \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nGoogle Cloud \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nAWS \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nDatabricks \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nSnowflake \\n\\n\\n\\n \\n \\n\\nPerspectivesNewsroom\\n\\n\\n\\n\\n\\n\\r\\n\\tNEWSROOM\\r\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNews & PR \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nEvents \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nAwards & Recognitions \\n\\n\\n\\n \\n \\n\\nContact Us  \\n \\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSERVICES\\n\\n\\n\\n\\nGo back\\n\\n\\n\\nSERVICES\\nStrategy & Advisory\\nAnalytics Roadmap\\nData Strategy\\nPlatform Design\\nEngineer Your Data\\nData Modernization\\nData Foundation\\nData Operations\\nDifferentiate with AI/ML\\nData Science\\nAI Engineering\\nML Products & Platforms\\nOperationalize Insights\\nExperience Consulting\\nApplication Engineering\\nBusiness Intelligence\\nMLOps'),\n",
       " Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content='OPEN IP\\n\\n\\n\\n\\nGo back\\n\\n\\n\\nOPEN IP\\nFoundations\\nTigerML\\nTiger Blueprints\\nTiger DataSphere\\nTiger AI Hub\\nSolutions\\nInsights Pro\\nMMX Planner\\nTrendSpotter\\nTPOptimizer\\nForecastPro\\nUWSmartFill\\n\\n\\n\\n\\nIMPACT\\n\\n\\n\\n\\nGo back\\n\\n\\n\\nIndustries\\nCPG\\nRetail\\nBFS\\nInsurance\\nManufacturing\\nTransportation & Logistics\\nLife Sciences\\nHealthcare\\nTechnology, Telecom & Media\\n\\n\\n\\n\\nABOUT US\\n\\n\\n\\n\\nGo back\\n\\n\\n\\nABOUT US\\nOur Story\\nWhy Join Us\\nCurrent Openings\\nOur Commitment to CSR\\n\\n\\n\\n\\nPARTNERSHIPS\\n\\n\\n\\n\\nGo back\\n\\n\\n\\nPARTNERSHIPS\\nMicrosoft\\nGoogle Cloud\\nAWS\\nDatabricks\\nSnowflake\\n\\n\\n\\nPERSPECTIVES\\n\\n\\n\\n\\nNEWSROOM\\n\\n\\n\\n\\nGo back\\n\\n\\n\\nNews & PR\\n\\nEvents\\nAwards\\n\\n\\n\\nCONTACT US\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTiger Analytics awarded the Deloitte India Technology Fast 50 Award 2024\\nRecognized for rapid growth and innovation as one of India’s fastest-growing technology companies.\\nKnow More\\n\\n\\n\\n\\n\\nTiger Analytics Collaborates with Zebra Technologies to Develop GenAI Next-Gen Solutions\\n\\nKnow More'),\n",
       " Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content='Tiger Analytics Collaborates with Zebra Technologies to Develop GenAI Next-Gen Solutions\\n\\nKnow More\\n\\n\\n\\n\\n\\n\\nVictoria’s Secret and Co. & Tiger Analytics: A Modernization Journey\\nLearn how VS&Co. modernized their analytics ecosystem by migrating from on-prem to Azure and Snowflake\\nRead more\\n\\n\\n\\n\\n\\nTiger Analytics Among India’s Best Workplaces in IT & IT-BPM 2024 and a Certified Great Place to Work®!\\nCommitted to exceptional people practices and fostering a positive work environment.\\nKnow More\\n\\n\\n\\n\\n\\nRanked a Leader and Star Performer in Everest Group PEAK Matrix® Assessment 2024\\nRanked for our strong IP, robust partnerships, and innovative solutions\\nDownload Report\\n\\n\\n\\n\\nTiger Analytics Recognized as a Leader by ISG in Retail Specialty Analytics Services\\n\\nKnow More\\n\\n\\nSCROLL\\n\\n\\n\\n\\nWHAT WE DO'),\n",
       " Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content='Tiger Analytics Recognized as a Leader by ISG in Retail Specialty Analytics Services\\n\\nKnow More\\n\\n\\nSCROLL\\n\\n\\n\\n\\nWHAT WE DO\\n\\nWe provide certainty by solving your toughest challenges\\nProblem-solving is not just about finding answers, but also about asking more questions until we know what will determine success and how to get there. Our focus is on helping you drive the right course of action, dispel ambiguity, and move ahead with confidence by bringing the best of AI and analytics together.\\n\\nRead our commitment to you \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat powers us? The Tiger Gene\\nAn attribute intrinsic to the exceptional teams at Tiger Analytics, this helps us unravel complexity and solve some of the toughest problems out there. An ownership mindset in all we do, a future-focused approach to solving problems, bringing the breadth and depth of expertise, and daring to experiment with unconventional methods to ultimately deliver value.\\n\\n\\nSee how we work\\nFind a career with us'),\n",
       " Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content=\"See how we work\\nFind a career with us\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPharma USA 2025\\nConnect with over 1,200 pharma leaders and solution providers at Pharma USA 2025 to explore innovative strategies with Tiger Analytics.\\n\\n\\n\\n\\nMarch 18 - 19, 2025Philadelphia, USA \\nRead More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShoptalk Spring\\nJoin 10,000+ retail innovators at Shoptalk Spring 2025. Discover trends and connect with leaders to transform retail with Tiger Analytics.\\n\\n\\n\\n\\nMarch 25 - 27, 2025Las Vegas, USA \\nRead More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGoogle Cloud Next 2025\\nMeet Tiger Analytics at Next 2025 - Google Cloud's flagship event for technology experts, enthusiasts, and innovators. Spread over three days, you get to discover what’s new and what’s next in gen AI, data, cloud infrastructure, the future of work, security, and more.\\n\\n\\n\\n\\nApril 09 - 11, 2025Las Vegas, USA \\nRead More\"),\n",
       " Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content='April 09 - 11, 2025Las Vegas, USA \\nRead More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSnowflake Summit 2025\\nJoin Tiger Analytics at Snowflake Summit 2025 – the premier event for data cloud enthusiasts and innovators. Across three days, dive into the latest advancements in data engineering, generative AI, analytics, collaboration, and Snowflake’s cutting-edge platform innovations shaping the future of data-driven business.\\n\\n\\n\\n\\nJune 02 - 05, 2025San Francisco, USA \\nRead More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDatabricks Data + AI Summit 2025\\nTiger Analytics invites you to the Databricks Data + AI Summit 2025 – the premier event for data, AI, and analytics enthusiasts. Explore the latest innovations in generative AI, big data, lakehouse platforms, machine learning, and more, shaping the future of data-driven decision-making.\\n\\n\\n\\n\\nJune 09 - 12, 2025San Francisco, USA \\nRead More'),\n",
       " Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content='June 09 - 12, 2025San Francisco, USA \\nRead More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDouble Gold for Tiger Analytics at Brandon Hall Group Awards 2024\\nAwarded for the Best Innovative L&D Program (Data Architect Foundation Program) and the Best Results of a Learning Program (Narrative Building Program).\\n\\n\\n\\n\\n\\nLearn More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTiger Analytics Wins Minsky Award for Excellence in AI Strategy Consulting\\nLeading the way in AI-powered business transformation across industries.\\n\\n\\n\\n\\n\\nKnow More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOur Tribe Makes All the Difference\\nWe are certified as a Great Place to Work®️ for yet another year.\\n\\n\\n\\n\\n\\nKnow More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTransform your enterprise data into intelligent action\\n\\n\\n\\n\\n\\nSTRATEGY AND ADVISORY\\nAnalytics Roadmap\\nData Strategy\\nPlatform Strategy\\n\\n\\nKnow more\\n\\n\\n\\n\\n\\nENGINEER YOUR DATA\\nData Modernization \\nData Foundation \\nData Operations\\n\\n\\nKnow more\\n\\n\\n\\n\\n\\nDIFFERENTIATE WITH AI/ML\\nData Science\\nAI Engineering \\nML Products & Platforms\\n\\n\\nKnow more'),\n",
       " Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content='Know more\\n\\n\\n\\n\\n\\nENGINEER YOUR DATA\\nData Modernization \\nData Foundation \\nData Operations\\n\\n\\nKnow more\\n\\n\\n\\n\\n\\nDIFFERENTIATE WITH AI/ML\\nData Science\\nAI Engineering \\nML Products & Platforms\\n\\n\\nKnow more\\n\\n\\n\\n\\n\\nOPERATIONALIZE INSIGHTS\\nExperience Consulting\\nApplication Engineering\\nBusiness Intelligence \\nML Ops\\n\\nKnow more\\n\\n\\n\\n\\n\\n\\n\\n\\nAugmenting industry best practices with AI and analytics\\n\\n\\n\\nEvery industry has its specific challenges, and there are no playbooks for many pressing ones. Balancing best practices and fundamental grounds-up thinking is needed to solve these.\\n\\nStart building now\\n\\n\\n\\n\\n\\n\\n\\n\\nOwn your AI journey with Tiger’s Open IP approach\\n\\n\\n\\nTiger’s easy-to-assemble accelerators and foundations, akin to Lego blocks, help speed up your AI development. As your AI and Analytics strategy evolves, our ready-to-deploy open-box solutions, will help power your growth story ensuring scalability and underscored by quality.\\n\\n\\nStart now'),\n",
       " Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content='Start now\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWe’ve partnered with the best to bring you the latest\\nRead about our partnerships \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGet inspired by the latest in the world of AI and analytics\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWHITE PAPER\\nA Guide to Synthetic Data Generation for Tabular Data\\nLearn how tabular synthetic data generation can address data scarcity and what organizations should consider when selecting vendor partners. \\n\\nDownload the White Paper \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBLOG\\n11 Ways Data Engineers Can Leverage an Agile Mindset to Help Drive Value Efficiently and Effectively\\nThis comprehensive guide explores how Agile methodologies can be applied to data engineering. It outlines key principles such as welcoming change, working in small increments, and continuous improvement. The article provides practical scenarios, pros and cons, and solutions for implementing Agile practices in data engineering projects.\\n\\nRead More'),\n",
       " Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content='Read More  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCASE STUDY\\nTiger Analytics Helps Inspiro Elevate Customer Experience Through a Data-Driven & Azure Open AI Based Knowledge Integration Solution\\nLearn how an OpenAI knowledge base tool built by Tiger Analytics was leveraged to improve Average Handling Time by 30% and Quality Assurance to 99%.\\n\\nLearn More \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBLOG\\nA Guide to Planning, Building and Launching GenAI Projects\\nLearn what questions business leaders need to be asking their teams and what frameworks and guidelines they can use to successfully harness Generative AI for their business.\\n\\nRead More \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBLOG\\nHow Enterprises are Navigating a Brave New Post GenAI Landscape\\nUncover how enterprises are navigating the transformative post-GenAI landscape catalyzed by ChatGPT’s disruption. \\n\\nRead More'),\n",
       " Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content='Read More \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nON-DEMAND WEBINAR\\nStart smart, win fast: Data Expert Talk on Data Modernization\\nIn this insightful webinar, experts from Tiger Analytics and AWS shed light how upgrading your data systems can unlock real-time insights, enhance agility, and provide a competitive edge in customer experience.\\n\\nWatch Webinar \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWHITE PAPER\\nTransforming Conversations, Empowering Businesses\\nLearn how organizations can leverage the potential of Natural Language Processing (NLP) and Generative AI (Gen AI) techniques to derive valuable business insights from customer conversations.\\n\\nDownload the White Paper \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAwards & Recognitions\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMinsky Award for Excellence in AI Strategy Consulting\\n2024\\n\\n\\n\\n\\n\\nDeloitte Technology Fast 50 Award\\n2024\\n\\n\\n \\n\\n\\nDouble Gold for Tiger Analytics at Brandon Hall Group Awards 2024\\n2024\\n \\n\\n\\n\\n\\nMicrosoft Partner of the Year Award for Business Transformation - AI Innovation in ASEAN\\n2024'),\n",
       " Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content=\"Double Gold for Tiger Analytics at Brandon Hall Group Awards 2024\\n2024\\n \\n\\n\\n\\n\\nMicrosoft Partner of the Year Award for Business Transformation - AI Innovation in ASEAN\\n2024\\n\\n\\n\\n\\n\\nTransforming Agriculture with AI: Tiger Analytics wins nasscom AI Gamechanger Award\\n2024\\n\\n\\n\\n\\n\\nRanked among Financial Times The Americas’ Fastest Growing Companies 2024\\n2024\\n\\n\\n\\n\\n\\nVaishnavi Kandala is recognized as 40 under 40 Data Scientist in India\\n2024\\n\\n\\n\\n\\n\\nLeader in AIM's PeMa Quadrant for Top MLOps Service Providers\\n2024\\n\\n\\n\\n\\n\\nRanked among Financial Times High Growth Companies Asia Pacific\\n2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nUnleash your full potential for a future of infinite possibilities\\nDiscover a meaningful career path in a collaborative environment.\\n\\n\\nApply now \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nServices\\nStrategy & Advisory\\n\\nAnalytics Roadmap\\nData Strategy\\nPlatform Strategy\\n\\nEngineer Your Data\\n\\nData Modernization\\nData Foundation\\nData Operations\\n\\nDifferentiate with AI/ML\"),\n",
       " Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content='Services\\nStrategy & Advisory\\n\\nAnalytics Roadmap\\nData Strategy\\nPlatform Strategy\\n\\nEngineer Your Data\\n\\nData Modernization\\nData Foundation\\nData Operations\\n\\nDifferentiate with AI/ML\\n\\nData Science\\nAI Engineering\\nML Products & Platforms\\n\\nOperationalize Insights\\n\\nExperience Consulting\\nApplication Engineering\\nBusiness Intelligence\\nMLOps\\n\\n\\n\\nOPEN IP\\nFoundations\\n\\nTigerML\\nTiger Blueprints\\nTiger DataSphere\\nTiger AI Hub\\n\\nSolutions\\n\\nInsights Pro\\nMMX Planner\\nTrendSpotter\\nTPOptimizer\\nForecastPro\\nUWSmartFill\\n\\n\\n\\nIMPACT\\nIndustries\\n\\nCPG\\nRetail\\nBFS\\nInsurance\\nManufacturing\\nTransportation & Logistics\\nLife Sciences\\nHealthcare\\nTechnology, Telecom & Media\\n\\n\\n\\n\\n\\n\\nABOUT US\\n\\nOur Story\\nWhy Join Us\\nCurrent Openings\\nOur Commitment to CSR\\n\\n\\nCONTACT US\\nFollow us on\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPartnerships\\n\\nMicrosoft\\nGoogle Cloud\\nAWS\\nDatabricks\\nSnowflake\\nPERSPECTIVES\\n\\n\\nNewsroom\\n\\nNews & PR\\n\\nEvents\\nAwards\\n\\n\\n\\n\\n\\t\\t\\t\\t\\tSubscribe to get latest insights\\n\\t\\t\\t\\t\\t\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tServices'),\n",
       " Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content='Newsroom\\n\\nNews & PR\\n\\nEvents\\nAwards\\n\\n\\n\\n\\n\\t\\t\\t\\t\\tSubscribe to get latest insights\\n\\t\\t\\t\\t\\t\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tServices\\n\\t\\t\\t\\t\\t\\t\\n\\n\\nSERVICES\\nStrategy & Advisory\\n\\nAnalytics Roadmap\\nData Strategy\\nPlatform Strategy\\n\\nEngineer Your Data\\n\\nData Modernization\\nData Foundation\\nData Operations\\n\\nDifferentiate with AI/ML\\n\\nData Science\\nAI Engineering\\nML Products & Platforms\\n\\nOperationalize Insights\\n\\nExperience Consulting\\nApplication Engineering\\nBusiness Intelligence\\nMLOps\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tOPEN IP\\n\\t\\t\\t\\t\\t\\t\\n\\n\\nOPEN IP\\nFoundations\\n\\nTigerML\\nTiger Blueprints\\nTiger DataSphere\\nTiger AI Hub\\n\\nSolutions\\n\\n\\nInsights Pro\\nMMX Planner\\nTrendSpotter\\nTPOptimizer\\nForecastPro\\nUWSmartFill\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tIMPACT\\n\\t\\t\\t\\t\\t\\t\\n\\n\\nIndustries\\n\\nCPG\\nRetail\\nBFS\\nInsurance\\nManufacturing\\nTransportation & Logistics\\nLife Sciences\\nHealthcare\\nTechnology, Telecom & Media\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tABOUT US\\n\\t\\t\\t\\t\\t\\t\\n\\n\\nABOUT US\\n\\nOur Story\\nWhy Join Us\\nCurrent Openings\\nOur Commitment to CSR\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tPartnerships'),\n",
       " Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content=\"ABOUT US\\n\\t\\t\\t\\t\\t\\t\\n\\n\\nABOUT US\\n\\nOur Story\\nWhy Join Us\\nCurrent Openings\\nOur Commitment to CSR\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tPartnerships\\n\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\nMicrosoft\\nGoogle Cloud\\nAWS\\nDatabricks\\nSnowflake\\n\\n\\n\\n\\nPerspectives\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tNewsroom\\n\\n\\n\\n\\n\\nNews & PR\\n\\nEvents\\nAwards\\n\\n\\n\\n\\nCONTACT US\\n\\n\\t\\t\\t\\tSubscribe to get latest insights\\n\\t\\t\\t\\t\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n×\\n\\n\\n\\n\\n\\n\\n\\nThank you!\\nWe will get in touch with you shortly.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n×\\n\\n\\n\\n\\n\\n\\n\\nThank you!\\nThe brochure has been emailed to you.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\tCopyright © 2025 Tiger Analytics | All Rights Reserved\\n\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\nPrivacy Notice\\nCookie Policy\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t        © 2023 TigerAnalytics. All rights reserved. \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tBook my Spot\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n*By submitting your details you acknowledge having read our privacy notice, consent to Tiger Analytics processing your data, and receive communications about Tiger Analytics' resources, events, products, or services.\"),\n",
       " Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content=\"What is 6 x 5? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tISG Retail Analytics Provider Lens Report 2024\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n*By submitting your details you acknowledge having read our privacy notice, consent to Tiger Analytics processing your data, and receive communications about Tiger Analytics' resources, events, products, or services.\\n\\n\\n\\nWhat is 3 + 6? \\n\\n\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tISG Supply Chain Analytics Provider Lens Report 2024\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n*By submitting your details you acknowledge having read our privacy notice, consent to Tiger Analytics processing your data, and receive communications about Tiger Analytics' resources, events, products, or services.\\n\\n\\n\\nWhat is 7 x 5? \\n\\n\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tWatch Video\"),\n",
       " Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content=\"What is 7 x 5? \\n\\n\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tWatch Video\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n*By submitting your details you acknowledge having read our  privacy notice, consent to Tiger Analytics processing your data, and receive communications about Tiger Analytics' resources, events, products, or services.\\n\\n\\n\\nWhat is 1 + 8? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tDownload Brochure\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n*By submitting your details you acknowledge having read our privacy notice, consent to Tiger Analytics processing your data, and receive communications about Tiger Analytics' resources, events, products, or services.\\n\\n\\n\\nWhat is 9 + 6? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tDownload Case Study\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n*By submitting your details you acknowledge having read our privacy notice, consent to Tiger Analytics processing your data, and receive communications about Tiger Analytics' resources, events, products, or services.\"),\n",
       " Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content=\"What is 5 + 6? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tDownload Brochure\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n*By submitting your details you acknowledge having read our privacy notice, consent to Tiger Analytics processing your data, and receive communications about Tiger Analytics' resources, events, products, or services.\\n\\n\\n\\nWhat is 5 + 7? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tDownload Brochure\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n*By submitting your details you acknowledge having read our privacy notice, consent to Tiger Analytics processing your data, and receive communications about Tiger Analytics' resources, events, products, or services.\\n\\n\\n\\nWhat is 2 + 9? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tDownload Brochure\"),\n",
       " Document(metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content=\"What is 2 + 9? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tDownload Brochure\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n*By submitting your details you acknowledge having read our privacy notice, consent to Tiger Analytics processing your data, and receive communications about Tiger Analytics' resources, events, products, or services.\\n\\n\\n\\nWhat is 5 + 6? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\")]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chunk and split the text \n",
    "# chunking techniques :\n",
    "# Text Splitter, Recursive Text Splitter, Recursive Text Splitter,...\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap = 200)\n",
    "document=text_splitter.split_documents(document)\n",
    "document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into embeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x249642b9370>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector store\n",
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstore = FAISS.from_documents(document, embeddings)\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tiger Analytics Recognized as a Leader by ISG in Retail Specialty Analytics Services\\n\\nKnow More\\n\\n\\nSCROLL\\n\\n\\n\\n\\nWHAT WE DO\\n\\nWe provide certainty by solving your toughest challenges\\nProblem-solving is not just about finding answers, but also about asking more questions until we know what will determine success and how to get there. Our focus is on helping you drive the right course of action, dispel ambiguity, and move ahead with confidence by bringing the best of AI and analytics together.\\n\\nRead our commitment to you \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat powers us? The Tiger Gene\\nAn attribute intrinsic to the exceptional teams at Tiger Analytics, this helps us unravel complexity and solve some of the toughest problems out there. An ownership mindset in all we do, a future-focused approach to solving problems, bringing the breadth and depth of expertise, and daring to experiment with unconventional methods to ultimately deliver value.\\n\\n\\nSee how we work\\nFind a career with us'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What powers us? The Tiger Gene\"\n",
    "result = vectorstore.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=' Answer the following question based only on the provided context:\\n                                 <context> {context} </context> '), additional_kwargs={})])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "ChatPromptTemplate.from_template(\"\"\" Answer the following question based only on the provided context:\n",
    "                                 <context> {context} </context> \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='60f74db5-34a4-4961-b97a-9aa0e4bb055e', metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content=\"What is 7 + 5? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tDownload Brochure\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n*By submitting your details you acknowledge having read our privacy notice, consent to Tiger Analytics processing your data, and receive communications about Tiger Analytics' resources, events, products, or services.\\n\\n\\n\\nWhat is 1 + 1? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\"),\n",
       " Document(id='5c59fc2e-1c82-4ff4-9a33-9a22cf7b1e0b', metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content='OPEN IP \\n \\n \\n\\n\\n\\n\\n\\r\\n\\tFoundations\\r\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTigerML \\n\\n\\n\\tRapidly prototype and deploy intuitive ML models\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\nTiger Blueprints \\n\\n\\n\\tSolve industry-specific business problems\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTiger DataSphere \\n\\n\\tAccelerators that bring speed, automation, and efficiency\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\nTiger AI Hub \\n\\n\\n\\tPre-built use cases and libraries to democratize AI workflows\\n\\n\\n \\n\\n\\n \\n \\n\\n\\n\\n\\n\\r\\n\\tSolutions\\r\\n \\n \\n\\n\\n\\n\\n\\n\\n\\r\\n\\t\\t\\tInsights Pro \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tMMX Planner \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tTrendSpotter \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tTPOptimizer \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tForecastPro\\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tUWSmartFill \\n\\n \\n \\n\\nImpact\\n\\n\\n\\n\\n\\n\\r\\n\\tIMPACT\\r\\n \\n \\n\\n\\n\\n\\n\\nIndustries \\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCPG \\n\\n\\nRetail \\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nBFS \\n\\n\\nInsurance \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nManufacturing \\n\\n\\nLogistics \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nLife Sciences \\n\\n\\nHealthcare \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nTechnology, Telecom & Media \\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\r\\n\\tBusiness Functions\\r\\n \\n \\n\\n\\n\\n\\n\\n\\n\\r\\n\\t\\t\\tMarketing \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tCustomer \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tSupply Chain \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tOperations & Planning \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tRisk \\n\\n \\n \\n\\nAbout Us\\n\\n\\n\\n\\n\\n\\r\\n\\tABOUT US'),\n",
       " Document(id='ef2ab0c2-69cc-4e00-a24f-e93216f131ae', metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content='Start now\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWe’ve partnered with the best to bring you the latest\\nRead about our partnerships \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGet inspired by the latest in the world of AI and analytics\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWHITE PAPER\\nA Guide to Synthetic Data Generation for Tabular Data\\nLearn how tabular synthetic data generation can address data scarcity and what organizations should consider when selecting vendor partners. \\n\\nDownload the White Paper \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBLOG\\n11 Ways Data Engineers Can Leverage an Agile Mindset to Help Drive Value Efficiently and Effectively\\nThis comprehensive guide explores how Agile methodologies can be applied to data engineering. It outlines key principles such as welcoming change, working in small increments, and continuous improvement. The article provides practical scenarios, pros and cons, and solutions for implementing Agile practices in data engineering projects.\\n\\nRead More'),\n",
       " Document(id='236c3354-ac62-4314-aa75-b80f68cbc897', metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content=\"What is 9 x 5? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tDownload Brochure\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n*By submitting your details you acknowledge having read our privacy notice, consent to Tiger Analytics processing your data, and receive communications about Tiger Analytics' resources, events, products, or services.\\n\\n\\n\\nWhat is 5 + 4? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tDownload Brochure\\t\\t\\t\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n*By submitting your details you acknowledge having read our privacy notice, consent to Tiger Analytics processing your data, and receive communications about Tiger Analytics' resources, events, products, or services.\\n\\n\\n\\nWhat is 7 + 5? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\tx\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tDownload Brochure\")]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"The input to this prompt template is a dictionary. We can play around with this prompt template by itself to see what it does by itself\"\n",
    "result = vectorstore.similarity_search(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instructions': 'Return a JSON object.'}, template='Answer the query.\\n{format_instructions}\\n{query}\\n')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
      "  context: RunnableLambda(format_docs)\n",
      "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
      "| PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='Summarize the following content: {context}')\n",
      "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000249642F7A70>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000024911706A80>, root_client=<openai.OpenAI object at 0x0000024962F5DC10>, root_async_client=<openai.AsyncOpenAI object at 0x00000249642F7110>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
      "| StrOutputParser() kwargs={} config={'run_name': 'stuff_documents_chain'} config_factories=[]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# Define a valid PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\"], \n",
    "    template=\"Summarize the following content: {context}\"\n",
    ")\n",
    "\n",
    "# Pass the correct prompt format\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "print(document_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"What are everyone's favorite colors:\\n\\n{context}\"), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000249646FFD70>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000249646FE240>, model_kwargs={}, openai_api_key='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', openai_proxy='')\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install -U langchain langchain-community\n",
    "\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"What are everyone's favorite colors:\\n\\n{context}\")]\n",
    ")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "chain = create_stuff_documents_chain(llm, prompt)\n",
    "chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nJesse's favorite color is red\\nJamal's favorite color is orange\""
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [\n",
    "    Document(page_content=\"Jesse loves red but not yellow\"),\n",
    "    Document(page_content = \"Jamal loves green but not as much as he loves orange\")\n",
    "]\n",
    "\n",
    "chain.invoke({\"context\": docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.web_base.WebBaseLoader at 0x24964725220>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\"https://python.langchain.com/docs/tutorials/llm_chain/\")\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/llm_chain/', 'title': 'Build a simple LLM application with chat models and prompt templates | 🦜️🔗 LangChain', 'description': \"In this quickstart we'll show you how to build a simple LLM application with LangChain. This application will translate text from English into another language. This is a relatively simple LLM application - it's just a single LLM call plus some prompting. Still, this is a great way to get started with LangChain - a lot of features can be built with just some prompting and an LLM call!\", 'language': 'en'}, page_content='\\n\\n\\n\\n\\nBuild a simple LLM application with chat models and prompt templates | 🦜️🔗 LangChain\\n\\n\\n\\n\\n\\n\\nSkip to main contentJoin us at  Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1💬SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain\\'s stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data directly to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem🦜🛠️ LangSmith🦜🕸️ LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyTutorialsBuild a simple LLM application with chat models and prompt templatesOn this pageBuild a simple LLM application with chat models and prompt templates\\nIn this quickstart we\\'ll show you how to build a simple LLM application with LangChain. This application will translate text from English into another language. This is a relatively simple LLM application - it\\'s just a single LLM call plus some prompting. Still, this is a great way to get started with LangChain - a lot of features can be built with just some prompting and an LLM call!\\nAfter reading this tutorial, you\\'ll have a high level overview of:\\n\\n\\nUsing language models\\n\\n\\nUsing prompt templates\\n\\n\\nDebugging and tracing your application using LangSmith\\n\\n\\nLet\\'s dive in!\\nSetup\\u200b\\nJupyter Notebook\\u200b\\nThis and other tutorials are perhaps most conveniently run in a Jupyter notebooks. Going through guides in an interactive environment is a great way to better understand them. See here for instructions on how to install.\\nInstallation\\u200b\\nTo install LangChain run:\\n\\nPipCondapip install langchainconda install langchain -c conda-forge\\nFor more details, see our Installation guide.\\nLangSmith\\u200b\\nMany of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls.\\nAs these applications get more and more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent.\\nThe best way to do this is with LangSmith.\\nAfter you sign up at the link above, make sure to set your environment variables to start logging traces:\\nexport LANGSMITH_TRACING=\"true\"export LANGSMITH_API_KEY=\"...\"\\nOr, if in a notebook, you can set them with:\\nimport getpassimport osos.environ[\"LANGSMITH_TRACING\"] = \"true\"os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()\\nUsing Language Models\\u200b\\nFirst up, let\\'s learn how to use a language model by itself. LangChain supports many different language models that you can use interchangeably. For details on getting started with a specific model, refer to supported integrations.\\n\\nSelect chat model:Groq▾GroqOpenAIAnthropicAzureGoogle VertexAWSCohereNVIDIAFireworks AIMistral AITogether AIIBM watsonxDatabrickspip install -qU \"langchain[groq]\"import getpassimport osif not os.environ.get(\"GROQ_API_KEY\"):  os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")from langchain.chat_models import init_chat_modelmodel = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")\\nLet\\'s first use the model directly. ChatModels are instances of LangChain Runnables, which means they expose a standard interface for interacting with them. To simply call the model, we can pass in a list of messages to the .invoke method.\\nfrom langchain_core.messages import HumanMessage, SystemMessagemessages = [    SystemMessage(\"Translate the following from English into Italian\"),    HumanMessage(\"hi!\"),]model.invoke(messages)API Reference:HumanMessage | SystemMessage\\nAIMessage(content=\\'Ciao!\\', additional_kwargs={\\'refusal\\': None}, response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 3, \\'prompt_tokens\\': 20, \\'total_tokens\\': 23, \\'completion_tokens_details\\': {\\'accepted_prediction_tokens\\': 0, \\'audio_tokens\\': 0, \\'reasoning_tokens\\': 0, \\'rejected_prediction_tokens\\': 0}, \\'prompt_tokens_details\\': {\\'audio_tokens\\': 0, \\'cached_tokens\\': 0}}, \\'model_name\\': \\'gpt-4o-mini-2024-07-18\\', \\'system_fingerprint\\': \\'fp_0705bf87c0\\', \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, id=\\'run-32654a56-627c-40e1-a141-ad9350bbfd3e-0\\', usage_metadata={\\'input_tokens\\': 20, \\'output_tokens\\': 3, \\'total_tokens\\': 23, \\'input_token_details\\': {\\'audio\\': 0, \\'cache_read\\': 0}, \\'output_token_details\\': {\\'audio\\': 0, \\'reasoning\\': 0}})\\ntipIf we\\'ve enabled LangSmith, we can see that this run is logged to LangSmith, and can see the LangSmith trace. The LangSmith trace reports token usage information, latency, standard model parameters (such as temperature), and other information.\\nNote that ChatModels receive message objects as input and generate message objects as output. In addition to text content, message objects convey conversational roles and hold important data, such as tool calls and token usage counts.\\nLangChain also supports chat model inputs via strings or OpenAI format. The following are equivalent:\\nmodel.invoke(\"Hello\")model.invoke([{\"role\": \"user\", \"content\": \"Hello\"}])model.invoke([HumanMessage(\"Hello\")])\\nStreaming\\u200b\\nBecause chat models are Runnables, they expose a standard interface that includes async and streaming modes of invocation. This allows us to stream individual tokens from a chat model:\\nfor token in model.stream(messages):    print(token.content, end=\"|\")\\n|C|iao|!||\\nYou can find more details on streaming chat model outputs in this guide.\\nPrompt Templates\\u200b\\nRight now we are passing a list of messages directly into the language model. Where does this list of messages come from? Usually, it is constructed from a combination of user input and application logic. This application logic usually takes the raw user input and transforms it into a list of messages ready to pass to the language model. Common transformations include adding a system message or formatting a template with the user input.\\nPrompt templates are a concept in LangChain designed to assist with this transformation. They take in raw user input and return data (a prompt) that is ready to pass into a language model.\\nLet\\'s create a prompt template here. It will take in two user variables:\\n\\nlanguage: The language to translate text into\\ntext: The text to translate\\n\\nfrom langchain_core.prompts import ChatPromptTemplatesystem_template = \"Translate the following from English into {language}\"prompt_template = ChatPromptTemplate.from_messages(    [(\"system\", system_template), (\"user\", \"{text}\")])API Reference:ChatPromptTemplate\\nNote that ChatPromptTemplate supports multiple message roles in a single template. We format the language parameter into the system message, and the user text into a user message.\\nThe input to this prompt template is a dictionary. We can play around with this prompt template by itself to see what it does by itself\\nprompt = prompt_template.invoke({\"language\": \"Italian\", \"text\": \"hi!\"})prompt\\nChatPromptValue(messages=[SystemMessage(content=\\'Translate the following from English into Italian\\', additional_kwargs={}, response_metadata={}), HumanMessage(content=\\'hi!\\', additional_kwargs={}, response_metadata={})])\\nWe can see that it returns a ChatPromptValue that consists of two messages. If we want to access the messages directly we do:\\nprompt.to_messages()\\n[SystemMessage(content=\\'Translate the following from English into Italian\\', additional_kwargs={}, response_metadata={}), HumanMessage(content=\\'hi!\\', additional_kwargs={}, response_metadata={})]\\nFinally, we can invoke the chat model on the formatted prompt:\\nresponse = model.invoke(prompt)print(response.content)\\nCiao!\\ntipMessage content can contain both text and content blocks with additional structure. See this guide for more information.\\nIf we take a look at the LangSmith trace, we can see exactly what prompt the chat model receives, along with token usage information, latency, standard model parameters (such as temperature), and other information.\\nConclusion\\u200b\\nThat\\'s it! In this tutorial you\\'ve learned how to create your first simple LLM application. You\\'ve learned how to work with language models, how to create a prompt template, and how to get great observability into applications you create with LangSmith.\\nThis just scratches the surface of what you will want to learn to become a proficient AI Engineer. Luckily - we\\'ve got a lot of other resources!\\nFor further reading on the core concepts of LangChain, we\\'ve got detailed Conceptual Guides.\\nIf you have more specific questions on these concepts, check out the following sections of the how-to guides:\\n\\nChat models\\nPrompt templates\\n\\nAnd the LangSmith docs:\\n\\nLangSmith\\nEdit this pageWas this page helpful?PreviousTutorialsNextBuild a ChatbotSetupJupyter NotebookInstallationLangSmithUsing Language ModelsStreamingPrompt TemplatesConclusionCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright © 2025 LangChain, Inc.\\n\\n')]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = loader.load()\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"What are everyone's favorite colors:\\n\\n{context}\"), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000249646FFD70>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000249646FE240>, model_kwargs={}, openai_api_key='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', openai_proxy='')\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "document_chain=create_stuff_documents_chain(llm,prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='fbdd74e8-9d89-4242-ae1a-32bd8d322024', metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content='Read More  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCASE STUDY\\nTiger Analytics Helps Inspiro Elevate Customer Experience Through a Data-Driven & Azure Open AI Based Knowledge Integration Solution\\nLearn how an OpenAI knowledge base tool built by Tiger Analytics was leveraged to improve Average Handling Time by 30% and Quality Assurance to 99%.\\n\\nLearn More \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBLOG\\nA Guide to Planning, Building and Launching GenAI Projects\\nLearn what questions business leaders need to be asking their teams and what frameworks and guidelines they can use to successfully harness Generative AI for their business.\\n\\nRead More \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBLOG\\nHow Enterprises are Navigating a Brave New Post GenAI Landscape\\nUncover how enterprises are navigating the transformative post-GenAI landscape catalyzed by ChatGPT’s disruption. \\n\\nRead More'),\n",
       " Document(id='4e5ab2d3-69f5-4a08-a826-8720affbddca', metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content='Read More \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nON-DEMAND WEBINAR\\nStart smart, win fast: Data Expert Talk on Data Modernization\\nIn this insightful webinar, experts from Tiger Analytics and AWS shed light how upgrading your data systems can unlock real-time insights, enhance agility, and provide a competitive edge in customer experience.\\n\\nWatch Webinar \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWHITE PAPER\\nTransforming Conversations, Empowering Businesses\\nLearn how organizations can leverage the potential of Natural Language Processing (NLP) and Generative AI (Gen AI) techniques to derive valuable business insights from customer conversations.\\n\\nDownload the White Paper \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAwards & Recognitions\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMinsky Award for Excellence in AI Strategy Consulting\\n2024\\n\\n\\n\\n\\n\\nDeloitte Technology Fast 50 Award\\n2024\\n\\n\\n \\n\\n\\nDouble Gold for Tiger Analytics at Brandon Hall Group Awards 2024\\n2024\\n \\n\\n\\n\\n\\nMicrosoft Partner of the Year Award for Business Transformation - AI Innovation in ASEAN\\n2024'),\n",
       " Document(id='9251f4b4-5f1d-4dca-8e8f-4c8d0fbba99e', metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content='OPEN IP \\n \\n \\n\\n\\n\\n\\n\\r\\n\\tFoundations\\r\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTigerML \\n\\n\\n\\tRapidly prototype and deploy intuitive ML models\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\nTiger Blueprints \\n\\n\\n\\tSolve industry-specific business problems\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTiger DataSphere \\n\\n\\tAccelerators that bring speed, automation, and efficiency\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\nTiger AI Hub \\n\\n\\n\\tPre-built use cases and libraries to democratize AI workflows\\n\\n\\n \\n\\n\\n \\n \\n\\n\\n\\n\\n\\r\\n\\tSolutions\\r\\n \\n \\n\\n\\n\\n\\n\\n\\n\\r\\n\\t\\t\\tInsights Pro \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tMMX Planner \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tTrendSpotter \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tTPOptimizer \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tForecastPro\\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tUWSmartFill \\n\\n \\n \\n\\nImpact\\n\\n\\n\\n\\n\\n\\r\\n\\tIMPACT\\r\\n \\n \\n\\n\\n\\n\\n\\nIndustries \\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCPG \\n\\n\\nRetail \\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nBFS \\n\\n\\nInsurance \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nManufacturing \\n\\n\\nLogistics \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nLife Sciences \\n\\n\\nHealthcare \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nTechnology, Telecom & Media \\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\r\\n\\tBusiness Functions\\r\\n \\n \\n\\n\\n\\n\\n\\n\\n\\r\\n\\t\\t\\tMarketing \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tCustomer \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tSupply Chain \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tOperations & Planning \\n\\n \\n\\n\\n\\n\\n\\r\\n\\t\\t\\tRisk \\n\\n \\n \\n\\nAbout Us\\n\\n\\n\\n\\n\\n\\r\\n\\tABOUT US'),\n",
       " Document(id='88f4f3f3-4b26-47c9-a20b-d2a4ebb621ea', metadata={'source': 'https://www.tigeranalytics.com/', 'title': 'Home - Tiger Analytics', 'language': 'en-US'}, page_content='Newsroom\\n\\nNews & PR\\n\\nEvents\\nAwards\\n\\n\\n\\n\\n\\t\\t\\t\\t\\tSubscribe to get latest insights\\n\\t\\t\\t\\t\\t\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tServices\\n\\t\\t\\t\\t\\t\\t\\n\\n\\nSERVICES\\nStrategy & Advisory\\n\\nAnalytics Roadmap\\nData Strategy\\nPlatform Strategy\\n\\nEngineer Your Data\\n\\nData Modernization\\nData Foundation\\nData Operations\\n\\nDifferentiate with AI/ML\\n\\nData Science\\nAI Engineering\\nML Products & Platforms\\n\\nOperationalize Insights\\n\\nExperience Consulting\\nApplication Engineering\\nBusiness Intelligence\\nMLOps\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tOPEN IP\\n\\t\\t\\t\\t\\t\\t\\n\\n\\nOPEN IP\\nFoundations\\n\\nTigerML\\nTiger Blueprints\\nTiger DataSphere\\nTiger AI Hub\\n\\nSolutions\\n\\n\\nInsights Pro\\nMMX Planner\\nTrendSpotter\\nTPOptimizer\\nForecastPro\\nUWSmartFill\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tIMPACT\\n\\t\\t\\t\\t\\t\\t\\n\\n\\nIndustries\\n\\nCPG\\nRetail\\nBFS\\nInsurance\\nManufacturing\\nTransportation & Logistics\\nLife Sciences\\nHealthcare\\nTechnology, Telecom & Media\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tABOUT US\\n\\t\\t\\t\\t\\t\\t\\n\\n\\nABOUT US\\n\\nOur Story\\nWhy Join Us\\nCurrent Openings\\nOur Commitment to CSR\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tPartnerships')]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search(\"Note that ChatModels receive message objects as inpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Red\\n2. Blue\\n3. Green\\n4. Purple\\n5. Pink'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_chain.invoke({\n",
    "    \"input\":\"Note that ChatModels receive message objects as input\",\n",
    "    \"context\":[Document(page_content=\"Note that ChatModels receive message objects as input and generate message objects as output. In addition to text content, message objects convey conversational roles and hold important data, such as tool calls and token usage counts.\\nLangChain also supports chat model inputs via strings or OpenAI format. The following are equivalent:\\nmodel.invoke('Hello')model.invoke([{'role': 'user', 'content': 'Hello'}])model.invoke([HumanMessage('Hello')]) StreamingBecause chat models are Runnables, they expose a standard interface that includes async and streaming modes of invocation. This allows us to stream individual tokens from a chat model:\\nfor token in model.stream(messages):    print(token.content, end='|')|C|iao|!|| You can find more details on streaming chat model outputs in this guide.\\nPrompt Templates\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000249642B9370>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"What are everyone's favorite colors:\\n\\n{context}\"), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000249646FFD70>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000249646FE240>, model_kwargs={}, openai_api_key='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', openai_proxy='')\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever=vectorstore.as_retriever() # context of retriver and retrival chain going to combine\n",
    "\n",
    "\n",
    "from langchain.chains import create_retrieval_chain\n",
    "# Integrate the context information coming via vector db\n",
    "retrieval_chain=create_retrieval_chain(retriever,document_chain)\n",
    "retrieval_chain\n",
    "\n",
    "# vectorStore | Runnable binding | prompt | llm | Stroutparser\n",
    "# document chain = prompt | llm | Stroutparser\n",
    "# we cannot add the vectorstore to document chain directly, it always convert  to runnable binding\n",
    "# How to convert into runnable binding - through retriver (vectorstore.as_retriver)\n",
    "# combining via document chain\n",
    "# Getting data from vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=retrieval_chain.invoke({\"input\":\"Note that ChatModels receive message objects as input\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm a language model AI and I don't have a favorite color.\""
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
